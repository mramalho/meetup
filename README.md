# AWS Community - Pipeline de TranscriÃ§Ã£o e Resumo Automatizado

Sistema completo para processamento automatizado de vÃ­deos que gera transcriÃ§Ãµes e resumos usando serviÃ§os da AWS. O projeto permite upload de vÃ­deos atravÃ©s de uma interface web, processamento automÃ¡tico via Amazon Transcribe e geraÃ§Ã£o de resumos inteligentes usando Amazon Bedrock.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Fluxo de Dados](#fluxo-de-dados)
- [Componentes](#componentes)
- [Requisitos](#requisitos)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [Deploy](#deploy)
- [Uso](#uso)
- [Scripts DisponÃ­veis](#scripts-disponÃ­veis)

## ğŸ¯ VisÃ£o Geral

Este projeto automatiza o processamento completo de vÃ­deos educacionais e palestras:

1. **Upload de VÃ­deos**: Interface web para upload de arquivos `.mp4`
2. **Prompt Personalizado**: OpÃ§Ã£o de enviar prompt customizado para personalizar os resumos
3. **TranscriÃ§Ã£o AutomÃ¡tica**: GeraÃ§Ã£o de legendas `.srt` via Amazon Transcribe
4. **Resumo Inteligente**: GeraÃ§Ã£o de resumos em Markdown via Amazon Bedrock (DeepSeek R1)
5. **Interface Web Moderna**: VisualizaÃ§Ã£o avanÃ§ada de Markdown com suporte a tabelas, diagramas Mermaid e syntax highlighting

## ğŸ—ï¸ Arquitetura

O sistema utiliza uma arquitetura serverless na AWS, composta por:

- **Frontend**: AplicaÃ§Ã£o web estÃ¡tica hospedada no S3 e distribuÃ­da via CloudFront
- **AutenticaÃ§Ã£o**: Cognito Identity Pool para acesso nÃ£o autenticado ao S3
- **Processamento**: FunÃ§Ãµes Lambda acionadas por eventos do S3
- **IA/ML**: Amazon Transcribe para transcriÃ§Ã£o e Amazon Bedrock para resumos
- **Armazenamento**: S3 para vÃ­deos, transcriÃ§Ãµes e resumos
- **OrquestraÃ§Ã£o**: EventBridge para coordenaÃ§Ã£o de eventos

### Diagrama de Arquitetura

```mermaid
graph TB
    User[ğŸ‘¤ UsuÃ¡rio] -->|1. Upload vÃ­deo| WebApp[ğŸŒ Interface Web<br/>S3 + CloudFront]
    WebApp -->|2. Upload via Cognito| S3Video[(ğŸ“¦ S3 Bucket<br/>video/)]
    
    S3Video -->|3. Evento Object Created| EventBridge[âš¡ EventBridge]
    EventBridge -->|4. Dispara| LambdaTranscribe[ğŸ”· Lambda<br/>start-transcribe]
    
    LambdaTranscribe -->|5. Inicia job| Transcribe[ğŸ™ï¸ Amazon Transcribe]
    Transcribe -->|6. Gera .srt| S3Transcribe[(ğŸ“¦ S3 Bucket<br/>transcribe/)]
    
    S3Transcribe -->|7. Evento Object Created| EventBridge2[âš¡ EventBridge]
    EventBridge2 -->|8. Dispara| LambdaBedrock[ğŸ”· Lambda<br/>bedrock-summary]
    
    LambdaBedrock -->|9. Extrai texto| S3Transcribe
    LambdaBedrock -->|10. Chama modelo| Bedrock[ğŸ¤– Amazon Bedrock<br/>DeepSeek R1]
    Bedrock -->|11. Retorna resumo| LambdaBedrock
    LambdaBedrock -->|12. Salva .md| S3Resumo[(ğŸ“¦ S3 Bucket<br/>resumo/)]
    
    WebApp -->|13. Lista arquivos| S3Transcribe
    WebApp -->|14. Lista arquivos| S3Resumo
    WebApp -->|15. Visualiza/Download| User
    
    style User fill:#e1f5ff
    style WebApp fill:#fff4e1
    style S3Video fill:#e8f5e9
    style S3Transcribe fill:#e8f5e9
    style S3Resumo fill:#e8f5e9
    style LambdaTranscribe fill:#f3e5f5
    style LambdaBedrock fill:#f3e5f5
    style Transcribe fill:#fff9c4
    style Bedrock fill:#fff9c4
    style EventBridge fill:#ffebee
    style EventBridge2 fill:#ffebee
```

## ğŸ”„ Fluxo de Dados

### Fluxo Completo

```mermaid
sequenceDiagram
    participant U as UsuÃ¡rio
    participant W as Web App
    participant S3V as S3 video/
    participant EB1 as EventBridge
    participant LT as Lambda Transcribe
    participant TR as Amazon Transcribe
    participant S3T as S3 transcribe/
    participant EB2 as EventBridge
    participant LB as Lambda Bedrock
    participant BR as Amazon Bedrock
    participant S3R as S3 resumo/

    U->>W: 1. Faz upload do vÃ­deo .mp4 (e opcionalmente prompt)
    W->>S3V: 2. Upload vÃ­deo para s3://bucket/video/
    W->>S3V: 2b. Upload prompt para s3://bucket/prompts/ (se fornecido)
    S3V->>EB1: 3. Dispara evento Object Created
    EB1->>LT: 4. Invoca Lambda
    LT->>TR: 5. Inicia TranscriptionJob
    TR->>S3T: 6. Salva arquivo .srt
    S3T->>EB2: 7. Dispara evento Object Created
    EB2->>LB: 8. Invoca Lambda
    LB->>S3T: 9. LÃª arquivo .srt
    LB->>S3V: 9b. Tenta ler prompt personalizado (se existir)
    LB->>LB: 10. Extrai texto puro do .srt
    LB->>BR: 11. Chama Bedrock Converse API (com prompt personalizado ou padrÃ£o)
    BR->>LB: 12. Retorna resumo em Markdown
    LB->>S3R: 13. Salva arquivo .md
    U->>W: 14. Atualiza lista de arquivos
    W->>S3T: 15. Lista arquivos .srt
    W->>S3R: 16. Lista arquivos .md
    U->>W: 17. Visualiza/baixa arquivos
```

## ğŸ§© Componentes

### Frontend (Interface Web)

- **LocalizaÃ§Ã£o**: `app/`
- **Tecnologias**: HTML5, CSS3, JavaScript (Vanilla)
- **Bibliotecas Externas**:
  - **Marked.js**: RenderizaÃ§Ã£o de Markdown
  - **Highlight.js**: Syntax highlighting para blocos de cÃ³digo
  - **DOMPurify**: SanitizaÃ§Ã£o de HTML para seguranÃ§a
  - **Mermaid.js**: RenderizaÃ§Ã£o de diagramas Mermaid
- **Hospedagem**: S3 + CloudFront
- **Layout**: Sidebar vertical Ã  esquerda com preview Ã  direita
- **Design**: Paleta monocromÃ¡tica (preto/cinza/branco)
- **Funcionalidades**:
  - Upload de vÃ­deos `.mp4` via Cognito Identity Pool
  - Upload de prompt personalizado (`.txt` ou `.md`) - opcional
  - Listagem de transcriÃ§Ãµes `.srt` e resumos `.md`
  - VisualizaÃ§Ã£o avanÃ§ada de Markdown com:
    - Suporte a GitHub Flavored Markdown (tabelas, task lists)
    - Diagramas Mermaid (flowcharts, sequence, gantt, etc.)
    - Syntax highlighting para cÃ³digo
    - RenderizaÃ§Ã£o de tabelas responsivas
  - Download de arquivos
  - Modo claro/escuro
  - BotÃµes de aÃ§Ã£o integrados (Atualizar, Dark Mode)
  - Logo AWS Community Campinas no header

### Backend (Serverless)

#### Lambda: `start-transcribe-on-s3-upload`
- **Trigger**: EventBridge (quando arquivo `.mp4` Ã© criado em `video/`)
- **FunÃ§Ã£o**: Inicia job de transcriÃ§Ã£o no Amazon Transcribe
- **Output**: Arquivo `.srt` salvo em `transcribe/`

#### Lambda: `generate-summary-from-srt-bedrock`
- **Trigger**: EventBridge (quando arquivo `.srt` Ã© criado em `transcribe/`)
- **FunÃ§Ã£o**: 
  - Extrai texto puro do arquivo `.srt`
  - Tenta ler prompt personalizado do S3 (`prompts/{nome_video}.txt`)
  - Se nÃ£o encontrar, usa prompt padrÃ£o hardcoded
  - Chama Amazon Bedrock (DeepSeek R1) para gerar resumo
  - Salva resumo em Markdown em `resumo/`

### Infraestrutura AWS

- **S3 Buckets**:
  - `aws-community-app`: Frontend estÃ¡tico
  - `aws-community-cps`: VÃ­deos, transcriÃ§Ãµes, resumos e prompts personalizados
    - `video/`: Arquivos de vÃ­deo `.mp4`
    - `transcribe/`: TranscriÃ§Ãµes `.srt`
    - `resumo/`: Resumos `.md`
    - `prompts/`: Prompts personalizados `.txt` (opcional)
- **CloudFront**: CDN para distribuiÃ§Ã£o do frontend
- **Route53**: DNS para domÃ­nio personalizado
- **ACM**: Certificado SSL/TLS
- **Cognito Identity Pool**: AutenticaÃ§Ã£o para acesso ao S3
- **EventBridge**: OrquestraÃ§Ã£o de eventos
- **IAM**: PolÃ­ticas de permissÃ£o

## ğŸ“‹ Requisitos

### PrÃ©-requisitos

- **AWS CLI** configurado com credenciais vÃ¡lidas
- **Terraform** >= 1.6.0
- **Python** 3.12 (para desenvolvimento local)
- **Bash** (para scripts de deploy)
- **Conta AWS** com permissÃµes para criar recursos

### PermissÃµes AWS NecessÃ¡rias

- Criar e gerenciar buckets S3
- Criar e gerenciar funÃ§Ãµes Lambda
- Criar e gerenciar EventBridge rules
- Criar e gerenciar Cognito Identity Pools
- Criar e gerenciar CloudFront distributions
- Criar e gerenciar Route53 records
- Acessar Amazon Transcribe
- Acessar Amazon Bedrock (com acesso ao modelo DeepSeek R1)

### ConfiguraÃ§Ã£o do Bedrock

1. Acesse o console do Amazon Bedrock
2. Solicite acesso ao modelo **DeepSeek R1** (ou use outro modelo compatÃ­vel)
3. Verifique que o inference profile `us.deepseek.r1-v1:0` estÃ¡ disponÃ­vel

## ğŸ“ Estrutura do Projeto

```
meetup/
â”œâ”€â”€ app/                          # Frontend estÃ¡tico
â”‚   â”œâ”€â”€ index.html               # PÃ¡gina principal
â”‚   â”œâ”€â”€ app.js                   # LÃ³gica JavaScript
â”‚   â”œâ”€â”€ styles.css               # Estilos CSS
â”‚   â”œâ”€â”€ error.html               # PÃ¡gina de erro 404
â”‚   â””â”€â”€ assets/                  # Assets estÃ¡ticos
â”‚       â””â”€â”€ logo.svg             # Logo AWS Community Campinas
â”‚
â”œâ”€â”€ terraform/                    # Infraestrutura como cÃ³digo
â”‚   â”œâ”€â”€ main.tf                  # Recursos principais
â”‚   â”œâ”€â”€ variables.tf             # VariÃ¡veis do Terraform
â”‚   â”œâ”€â”€ outputs.tf               # Outputs do Terraform
â”‚   â”œâ”€â”€ terraform.tfvars         # Valores das variÃ¡veis (nÃ£o versionado)
â”‚   â”œâ”€â”€ lambda/                  # CÃ³digo das Lambdas
â”‚   â”‚   â”œâ”€â”€ lambda_function.py   # Lambda de transcriÃ§Ã£o
â”‚   â”‚   â””â”€â”€ lambda_bedrock_summary.py  # Lambda de resumo
â”‚   â””â”€â”€ build/                   # Arquivos ZIP das Lambdas
â”‚       â”œâ”€â”€ start_transcribe.zip
â”‚       â””â”€â”€ bedrock_summary.zip
â”‚
â”œâ”€â”€ script/                       # Scripts de automaÃ§Ã£o
â”‚   â”œâ”€â”€ build_lambdas.sh         # Build das Lambdas
â”‚   â”œâ”€â”€ deploy_app.sh            # Deploy do frontend
â”‚   â”œâ”€â”€ terraform_deploy.sh      # Deploy da infraestrutura
â”‚   â””â”€â”€ clear_files.sh           # Limpeza de arquivos S3
â”‚
â”œâ”€â”€ .gitignore                   # Arquivos ignorados pelo Git
â””â”€â”€ README.md                    # Este arquivo
```

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. VariÃ¡veis do Terraform

Crie um arquivo `terraform/terraform.tfvars` com suas configuraÃ§Ãµes:

```hcl
aws_region = "us-east-2"

app_bucket_name = "aws-community-app"
cps_bucket_name = "aws-community-cps"

domain_name = "meetup.ramalho.dev.br"

# Certificado ACM (deve estar em us-east-1 para CloudFront)
acm_certificate_arn = "arn:aws:acm:us-east-1:ACCOUNT_ID:certificate/CERT_ID"

# Hosted Zone do Route53
hosted_zone_id = "Z1234567890ABC"

# ConfiguraÃ§Ãµes do Bedrock
bedrock_region = "us-east-2"
bedrock_model_id = "deepseek.r1-v1:0"
bedrock_inference_profile = "us.deepseek.r1-v1:0"
```

### 2. ConfiguraÃ§Ã£o do Frontend

Atualize o `IdentityPoolId` no arquivo `app/app.js` apÃ³s o deploy do Terraform:

```javascript
AWS.config.update({
  region: "us-east-2",
  credentials: new AWS.CognitoIdentityCredentials({
    IdentityPoolId: "us-east-2:SEU_IDENTITY_POOL_ID"  // Obtenha do output do Terraform
  })
});
```

## ğŸš€ Deploy

### 1. Build das Lambdas

```bash
bash script/build_lambdas.sh
```

Este script:
- Cria o diretÃ³rio `terraform/build/` se nÃ£o existir
- Empacota as funÃ§Ãµes Lambda em arquivos ZIP

### 2. Deploy da Infraestrutura

```bash
bash script/terraform_deploy.sh
```

Ou manualmente:

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

**Importante**: Anote o `identity_pool_id` do output do Terraform e atualize o `app.js`.

### 3. Deploy do Frontend

```bash
bash script/deploy_app.sh
```

Este script:
- Faz sync dos arquivos do `app/` para o bucket S3
- Invalida o cache do CloudFront

## ğŸ’» Uso

### Acessando a Interface

ApÃ³s o deploy, acesse o site atravÃ©s do domÃ­nio configurado (ex: `https://meetup.ramalho.dev.br`).

### Upload de VÃ­deo

1. Clique em "Choose File" e selecione um arquivo `.mp4`
2. (Opcional) Selecione um arquivo de prompt personalizado (`.txt` ou `.md`)
   - O prompt serÃ¡ usado para personalizar o resumo gerado
   - Se nÃ£o enviar, serÃ¡ usado o prompt padrÃ£o
3. Clique em "Enviar"
4. Aguarde a confirmaÃ§Ã£o de upload

### Processamento AutomÃ¡tico

O processamento acontece automaticamente:

1. **TranscriÃ§Ã£o** (alguns minutos):
   - O vÃ­deo Ã© processado pelo Amazon Transcribe
   - Arquivo `.srt` Ã© gerado e salvo em `transcribe/`

2. **Resumo** (alguns minutos apÃ³s a transcriÃ§Ã£o):
   - O texto Ã© extraÃ­do do `.srt`
   - Se um prompt personalizado foi enviado, ele Ã© lido do S3 (`prompts/{nome_video}.txt`)
   - Caso contrÃ¡rio, Ã© usado o prompt padrÃ£o
   - Resumo Ã© gerado pelo Amazon Bedrock usando o prompt selecionado
   - Arquivo `.md` Ã© salvo em `resumo/`

### Prompt Personalizado

VocÃª pode personalizar os resumos enviando um arquivo de prompt junto com o vÃ­deo:

- **Formato**: Arquivo de texto (`.txt` ou `.md`)
- **Nome**: O arquivo serÃ¡ salvo como `{nome_do_video}.txt` no bucket
- **Uso**: O prompt serÃ¡ usado como instruÃ§Ã£o para o modelo de IA ao gerar o resumo
- **Exemplo**: Um prompt pode instruir o modelo a focar em pontos tÃ©cnicos, criar seÃ§Ãµes especÃ­ficas, ou usar um formato particular

**Nota**: Se nenhum prompt for enviado, o sistema usa um prompt padrÃ£o otimizado para resumos de palestras e vÃ­deos tÃ©cnicos.

### VisualizaÃ§Ã£o

1. Use as abas "TranscriÃ§Ãµes (.srt)" e "Resumos (.md)" para alternar entre os tipos
2. Clique em um arquivo para visualizar o conteÃºdo
3. Os resumos Markdown suportam:
   - **Tabelas**: RenderizaÃ§Ã£o completa de tabelas GitHub Flavored Markdown
   - **Diagramas Mermaid**: Flowcharts, sequence diagrams, Gantt charts, etc.
   - **Syntax Highlighting**: CÃ³digo com destaque de sintaxe
   - **Task Lists**: Listas de tarefas interativas
4. Use o botÃ£o "Baixar arquivo" para fazer download

## ğŸ› ï¸ Scripts DisponÃ­veis

### `build_lambdas.sh`
Empacota as funÃ§Ãµes Lambda em arquivos ZIP para deploy.

```bash
bash script/build_lambdas.sh
```

### `deploy_app.sh`
Faz deploy do frontend para o S3 e invalida o cache do CloudFront.

```bash
bash script/deploy_app.sh
```

### `terraform_deploy.sh`
Inicializa e aplica a infraestrutura com Terraform.

```bash
bash script/terraform_deploy.sh
```

### `clear_files.sh`
**âš ï¸ CUIDADO**: Apaga todos os arquivos dos diretÃ³rios `video/` e `transcribe/` do bucket S3.

```bash
bash script/clear_files.sh
```

## ğŸ”§ ManutenÃ§Ã£o

### Atualizar CÃ³digo das Lambdas

1. Edite os arquivos em `terraform/lambda/`
2. Execute `bash script/build_lambdas.sh`
3. Execute `terraform apply` na pasta `terraform/`

### Atualizar Frontend

1. Edite os arquivos em `app/`
2. Se adicionar novos assets, certifique-se de que estÃ£o na pasta `app/assets/`
3. Execute `bash script/deploy_app.sh`

### Verificar Logs

```bash
# Logs da Lambda de TranscriÃ§Ã£o
aws logs tail /aws/lambda/start-transcribe-on-s3-upload --follow

# Logs da Lambda de Resumo
aws logs tail /aws/lambda/generate-summary-from-srt-bedrock --follow
```

## ğŸ“Š Custos Estimados

Os custos variam conforme o uso, mas os principais componentes sÃ£o:

- **S3**: Armazenamento e requisiÃ§Ãµes (~$0.023/GB/mÃªs)
- **Lambda**: ExecuÃ§Ãµes e duraÃ§Ã£o (~$0.20 por 1M requisiÃ§Ãµes)
- **Transcribe**: Por minuto de Ã¡udio processado (~$0.024/minuto)
- **Bedrock**: Por token processado (varia por modelo)
- **CloudFront**: TransferÃªncia de dados (~$0.085/GB)
- **EventBridge**: Primeiros 14M eventos/mÃªs sÃ£o gratuitos

## ğŸ”’ SeguranÃ§a

- **Cognito Identity Pool**: Acesso nÃ£o autenticado com permissÃµes limitadas apenas aos prefixos necessÃ¡rios
- **IAM Policies**: PrincÃ­pio do menor privilÃ©gio aplicado
- **S3 Bucket Policies**: Acesso pÃºblico apenas para o bucket do frontend
- **CloudFront**: HTTPS obrigatÃ³rio com certificado SSL/TLS
- **VariÃ¡veis SensÃ­veis**: Armazenadas em variÃ¡veis de ambiente das Lambdas

## ğŸ› Troubleshooting

### Erro no Upload

- Verifique se o `IdentityPoolId` no `app.js` estÃ¡ correto
- Verifique as permissÃµes do Cognito Identity Pool
- Verifique os logs do navegador (F12)

### TranscriÃ§Ã£o nÃ£o Ã© gerada

- Verifique os logs da Lambda `start-transcribe-on-s3-upload`
- Verifique se o EventBridge estÃ¡ configurado corretamente
- Verifique se o Amazon Transcribe tem acesso ao bucket

### Resumo nÃ£o Ã© gerado

- Verifique os logs da Lambda `generate-summary-from-srt-bedrock`
- Verifique se o acesso ao Bedrock estÃ¡ habilitado
- Verifique se o inference profile estÃ¡ correto
- Verifique se o prompt personalizado (se usado) estÃ¡ no formato correto e no bucket correto

### Site nÃ£o carrega

- Verifique se o CloudFront estÃ¡ distribuindo corretamente
- Verifique se o certificado SSL estÃ¡ vÃ¡lido
- Verifique os logs do CloudFront

## ğŸ“ LicenÃ§a

Este projeto Ã© fornecido como estÃ¡, sem garantias.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests.

## ğŸ“§ Contato

**Autor:** Marcos Ramalho

**E-mail:** mramalho@gmail.com

**LinkedIn:** [www.linkedin.com/in/ramalho.dev](https://www.linkedin.com/in/ramalho.dev)

---

**Desenvolvido com â¤ï¸ usando AWS Serverless**


